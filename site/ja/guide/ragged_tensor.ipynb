{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ragged_tensor.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nibpbUnTsxTd"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tXAbWHtqs1Y2",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HTgMAvQq-PU_"
      },
      "source": [
        "# Ragged tensorsとは\n",
        "\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/ragged_tensor\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/ragged_tensor.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/guide/ragged_tensor.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cDIUjj07-rQg"
      },
      "source": [
        "## セットアップ\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KKvdSorS-pDD",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import math\n",
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pxi0m_yf-te5"
      },
      "source": [
        "## Overview\n",
        "\n",
        "様々なデータは本来、バラバラな形を持っているはずです。\n",
        "「Ragged Tensor」とはTensorFlowにおけるネストされたリスト型のような可変長のデータを扱うことができます。\n",
        "Ragged Tensorを使えば、可変長データを簡単に扱うことができます。\n",
        "例えば、\n",
        "\n",
        "\n",
        "*   映画の役者リストのような可変長のデータ\n",
        "*   文章や映像といった、時系列データのまとまり\n",
        "*   章、段落、文章、単語といったヒエラルキー構造な入力データ\n",
        "*   Protocol Buffersのような個々の構造体データ\n",
        "\n",
        "### Ragged Tensorでできること\n",
        "\n",
        "\n",
        "Ragged tensorsは、`tf.add`や`tf.reduce_mean`のような数学的オペレーション、`tf.concat`や\n",
        "`tf.tile`といった行列オペレーションを含む、100以上のTensorFlowオペレーションに対応しています。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vGmJGSf_-PVB",
        "colab": {}
      },
      "source": [
        "digits = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])\n",
        "words = tf.ragged.constant([[\"So\", \"long\"], [\"thanks\", \"for\", \"all\", \"the\", \"fish\"]])\n",
        "print(tf.add(digits, 3))\n",
        "print(tf.reduce_mean(digits, axis=1))\n",
        "print(tf.concat([digits, [[5, 3]]], axis=0))\n",
        "print(tf.tile(digits, [1, 2]))\n",
        "print(tf.strings.substr(words, 0, 2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Pt-5OIc8-PVG"
      },
      "source": [
        "Ragged Tensor特有の、Factory MethodsやConversion Methods、値を変換するオペレーションも存在\n",
        "します。 リストオペレーションについては`tf.ragged`パッケージのドキュメントを参考にしてください。\n",
        "\n",
        "通常のテンソルのように、Pythonライクなインデックス指定を行ったり、Slice指定を扱うこと\n",
        "ができます。詳しくは**インデックス指定**の項を参考にしてください。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n8YMKXpI-PVH",
        "colab": {}
      },
      "source": [
        "print(digits[0])       # 最初の行"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Awi8i9q5_DuX",
        "colab": {}
      },
      "source": [
        "print(digits[:, :2])   # 各行、最初の２つの値を取得"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sXgQtTcgHHMR",
        "colab": {}
      },
      "source": [
        "print(digits[:, -2:])  # 各行、最後の２つの値を取得"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6FU5T_-8-PVK"
      },
      "source": [
        "また、通常のTensorのように、Python算術演算子、比較演算子を使うことができます。詳細は、\n",
        "オーバーロードオペレーションを参考にしてください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2tdUEtb7-PVL",
        "colab": {}
      },
      "source": [
        "print(digits + 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "X-bxG0nc_Nmf",
        "colab": {}
      },
      "source": [
        "print(digits + tf.ragged.constant([[1, 2, 3, 4], [], [5, 6, 7], [8], []]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2tsw8mN0ESIT"
      },
      "source": [
        "もし、`RaggedTensor`の各要素に変換をかけたい場合は、`tf.ragged.map_flat_values`を使うことが\n",
        "できます。これは`function`と`RaggedTensor`を引数にもち、下記のように変換をすることができます。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pvt5URbdEt-D",
        "colab": {}
      },
      "source": [
        "times_two_plus_one = lambda x: x * 2 + 1\n",
        "print(tf.ragged.map_flat_values(times_two_plus_one, digits))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7M5RHOgp-PVN"
      },
      "source": [
        "### Ragged Tensorを作る\n",
        "Ragged Tensorを作る一番手っ取り早い方法は、`tf.ragged.constant`を使うことです。\n",
        "Pythonのネストされた`list`からRagged Tensorを作成することができます。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yhgKMozw-PVP",
        "colab": {}
      },
      "source": [
        "sentences = tf.ragged.constant([\n",
        "    [\"Let's\", \"build\", \"some\", \"ragged\", \"tensors\", \"!\"],\n",
        "    [\"We\", \"can\", \"use\", \"tf.ragged.constant\", \".\"]])\n",
        "print(sentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TW1g7eE2ee8M",
        "colab": {}
      },
      "source": [
        "paragraphs = tf.ragged.constant([\n",
        "    [['I', 'have', 'a', 'cat'], ['His', 'name', 'is', 'Mat']],\n",
        "    [['Do', 'you', 'want', 'to', 'come', 'visit'], [\"I'm\", 'free', 'tomorrow']],\n",
        "])\n",
        "print(paragraphs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SPLn5xHn-PVR"
      },
      "source": [
        "Ragged Tensorは２つの要素から構成されています。それはデータを構成する*values*Tensorと、\n",
        "それを行に分割していく*row-partitioning*Tensorです。 分割の仕方によって３つのClassメソッド、\n",
        "`tf.RaggedTensor.from_value_rowids`、`tf.RaggedTensor.from_row_lengths`および、\n",
        "`tf.RaggedTensor.from_row_splits`が定義されています。\n",
        "\n",
        "#### `tf.RaggedTensor.from_value_rowids`\n",
        "もし、各要素がどの列に入るのか事前に指定したい場合は、`value_rowids`による分割用Tensorを用いて\n",
        "`RaggedTensor`をビルドすることができます。\n",
        "\n",
        "![value_rowids](https://www.tensorflow.org/images/ragged_tensors/value_rowids.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SEvcPUcl-PVS",
        "colab": {}
      },
      "source": [
        "print(tf.RaggedTensor.from_value_rowids(\n",
        "    values=[3, 1, 4, 1, 5, 9, 2, 6],\n",
        "    value_rowids=[0, 0, 0, 0, 2, 2, 2, 3]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RBQh8sYc-PVV"
      },
      "source": [
        "#### `tf.RaggedTensor.from_row_lengths`\n",
        "\n",
        "長さを用いて列に分割したいのなら、`row_lengths`による分割用Tensorを用いて`RaggedTensor`をビルドできます。\n",
        "\n",
        "![row_lengths](https://www.tensorflow.org/images/ragged_tensors/row_lengths.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LBY81WXl-PVW",
        "colab": {}
      },
      "source": [
        "print(tf.RaggedTensor.from_row_lengths(\n",
        "    values=[3, 1, 4, 1, 5, 9, 2, 6],\n",
        "    row_lengths=[4, 0, 3, 1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8p5V8_Iu-PVa"
      },
      "source": [
        "#### `tf.RaggedTensor.from_row_splits`\n",
        "\n",
        "分割点を用いて列に分割したいのなら、`row_splits`による分割用Tensorを用いて`RaggedTensor`\n",
        "をビルドできます。\n",
        "\n",
        "![row_splits](https://www.tensorflow.org/images/ragged_tensors/row_splits.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FwizuqZI-PVb",
        "colab": {}
      },
      "source": [
        "print(tf.RaggedTensor.from_row_splits(\n",
        "    values=[3, 1, 4, 1, 5, 9, 2, 6],\n",
        "    row_splits=[0, 4, 4, 7, 8]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "E-9imo8DhwuA"
      },
      "source": [
        "また、その他のビルド方法に関しては、`tf.RaggedTensor`クラスのリファレンスを参考にしてください。 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YQAOsT1_-PVg"
      },
      "source": [
        "### RaggedTensorに入れられるデータ\n",
        "\n",
        "`RaggedTensor`は通常の`Tensor`のように、全てのデータは必ず同じ型でなければなりません。\n",
        "また、ネストの深さも一様に同じでなければなりません。(ネストの深さとは、Tensorの*rank*のことです。)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SqbPBd_w-PVi",
        "colab": {}
      },
      "source": [
        "print(tf.ragged.constant([[\"Hi\"], [\"How\", \"are\", \"you\"]]))  # ok: type=string, rank=2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "83ZCSJnQAWAf",
        "colab": {}
      },
      "source": [
        "print(tf.ragged.constant([[[1, 2], [3]], [[4, 5]]]))        # ok: type=int32, rank=3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ewA3cISdDfmP",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  tf.ragged.constant([[\"one\", \"two\"], [3, 4]])              # bad: 複数の type\n",
        "except ValueError as exception:\n",
        "  print(exception)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EOWIlVidDl-n",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  tf.ragged.constant([\"A\", [\"B\", \"C\"]])                     # bad: 複雑なネスト\n",
        "except ValueError as exception:\n",
        "  print(exception)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nhHMFhSp-PVq"
      },
      "source": [
        "### ユースケース\n",
        "\n",
        "今回の例では、可変長な全文章データを`RaggedTensor`を使ってunigramおよびbigramを構成し、\n",
        "さらにそれらをEmbedding表現を混ぜ込む方法を解説します。\n",
        "これらの機能についての詳しい解説は、`tf.ragged`パッケージのリファレンスを参考にしてください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZBs_V7e--PVr",
        "colab": {}
      },
      "source": [
        "queries = tf.ragged.constant([['Who', 'is', 'Dan', 'Smith'],\n",
        "                              ['Pause'],\n",
        "                              ['Will', 'it', 'rain', 'later', 'today']])\n",
        "\n",
        "# Embedding 用のテーブルを作成します。\n",
        "num_buckets = 1024\n",
        "embedding_size = 4\n",
        "embedding_table = tf.Variable(\n",
        "    tf.random.truncated_normal([num_buckets, embedding_size],\n",
        "                       stddev=1.0 / math.sqrt(embedding_size)))\n",
        "\n",
        "# Embedding用に単語をそれぞれ数値(?)に変換し、Embeddingします。\n",
        "word_buckets = tf.strings.to_hash_bucket_fast(queries, num_buckets)\n",
        "word_embeddings = tf.ragged.map_flat_values(\n",
        "    tf.nn.embedding_lookup, embedding_table, word_buckets)                  # ①\n",
        "\n",
        "# 文の最初と最後にbigramのためのマークをつけます。\n",
        "marker = tf.fill([queries.nrows(), 1], '#')\n",
        "padded = tf.concat([marker, queries, marker], axis=1)                       # ②\n",
        "\n",
        "# 単語のbigramを構築し、bigram単語を数値(?)に変換の後、Embeddingします。\n",
        "bigrams = tf.strings.join([padded[:, :-1],\n",
        "                               padded[:, 1:]],\n",
        "                              separator='+')                                # ③\n",
        "\n",
        "bigram_buckets = tf.strings.to_hash_bucket_fast(bigrams, num_buckets)\n",
        "bigram_embeddings = tf.ragged.map_flat_values(\n",
        "    tf.nn.embedding_lookup, embedding_table, bigram_buckets)                # ④\n",
        "\n",
        "# 最後に文ごとにEmbeddingベクトルの平均値をとります。\n",
        "all_embeddings = tf.concat([word_embeddings, bigram_embeddings], axis=1)    # ⑤\n",
        "avg_embedding = tf.reduce_mean(all_embeddings, axis=1)                      # ⑥\n",
        "print(avg_embedding)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y_lE_LAVcWQH"
      },
      "source": [
        "![ragged_example](https://www.tensorflow.org/images/ragged_tensors/ragged_example.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "An_k0pX1-PVt"
      },
      "source": [
        "## Ragged Tensorの詳細\n",
        "\n",
        "### Raggedでありながら一部分固定長を持つ方法\n",
        "\n",
        "*ragged tensor*というのも、詳細に言えば*ragged dimention*をもつ次元の表現の一つで(?)、\n",
        "ある特定の次元だけ可変長であるということもできます。　\n",
        "例えば、`rt=[[3, 1, 4, 1], [], [5, 9, 2], [6], []]`の１つ内側の次元はRaggedな次元です。\n",
        "それはもちろん、sliceをしてみる(`rt[0, :]`, ..., `rt[4, :]`)と違う長さのデータが出てくるから\n",
        "です。ですが、内側のSliceでも次元が固定された状態の*uniform dimensions*をRaggedTensorで\n",
        "構成することができます。\n",
        "  \n",
        "スライスによる次元は一定なので(?)一番外側の次元は必ず固定長です。(また、スライスによって次元\n",
        "が変わる可能性がない)\n",
        "また一番外側の次元と同じように、内側の次元でも固定長で扱うことができます。例えば、Word Embedding\n",
        "では、Word部分となるRaggedTensorと、外側のBatchの次元と、さらにEmbeddingの次元も加えて\n",
        "`[num_sentences, (num_words), embedding_size]`と表現できます。\n",
        "ここでいう`(num_words)`がRaggedな次元となります。\n",
        "  \n",
        "\n",
        "![sent_word_embed](https://www.tensorflow.org/images/ragged_tensors/sent_word_embed.png)\n",
        "\n",
        "また、RaggedTensorは複数のRaggedな次元を持つことができます。 例えば、文章を`[num_documents,\n",
        "(num_paragraphs), (num_sentences), (num_words)]`のようにBatch化して、\n",
        "処理することも可能です。(括弧で括られたところが、Raggedな次元と表現しています。)\n",
        "\n",
        "#### Ragged tensor のShapeに関する制限\n",
        "\n",
        "Ragged TensorのShapeは現時点では以下のように制限されています。\n",
        "\n",
        "*   一番外側だけは固定長の次元（？）\n",
        "*   一つ以上の可変長の次元が存在\n",
        "*   ０以上の固定長次元が存在\n",
        "\n",
        "Note: これらの制限は実装の結果であり、今後制限が緩和されるかもしれません。\n",
        "\n",
        "### Rank and ragged rank\n",
        "\n",
        "Raggedな次元を含め、Ragged Tensorの全ての次元の数のことを***rank***と呼びます。また、Ragged\n",
        "な次元だけを数えた次元数は***ragged rank***と呼びます。 graph execution mode(つまり、\n",
        "non-earger mode)であるとき、Tensorのragged rankについては作成時に固定されます。つまり、\n",
        "runtime valuesに依存することができない上、異なるsession runの中で動的に変えることもできません。\n",
        "  \n",
        "***potentially ragged tensor***とは、`tf.Tensor`か`tf.RaggedTensor`のどちらかの状態の\n",
        "ことを指します。 また、`tf.Tensor`のragged rankは常に0と定義されています。\n",
        "\n",
        "### RaggedTensor shapes\n",
        "\n",
        "Ragged TensorのShapeについて述べる際、ragged な次元はカッコで括ります。例えば、上述の通り、\n",
        "各単語のEmbedding表現のデータをもつRaggedTensorを\n",
        "`[num_sentences, (num_words), embedding_size]`と表しています。\n",
        "また、`RaggedTensor.shape`アトリビュートはRaggedな次元が`None`になった\n",
        "`tf.TensorShape`を返します。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M2Wzx4JEIvmb",
        "colab": {}
      },
      "source": [
        "tf.ragged.constant([[\"Hi\"], [\"How\", \"are\", \"you\"]]).shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G9tfJOeFlijE"
      },
      "source": [
        "`tf.RaggedTensor.bounding_shape`は`RaggedTensor`がPadding等をして(意訳)固定長で入れる際\n",
        "のshapeを返します。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5DHaqXHxlWi0",
        "colab": {}
      },
      "source": [
        "print(tf.ragged.constant([[\"Hi\"], [\"How\", \"are\", \"you\"]]).bounding_shape())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "V8e7x95UcLS6"
      },
      "source": [
        "## Ragged vs sparse tensors\n",
        "\n",
        "Ragged Tensorはsparse tensorとは*違いますが*、\n",
        "同じ不規則なテンソル型としての密なテンソル型を表現する表現の一つであると考えて良いでしょう。\n",
        "\n",
        "Ragged TensorとSparse Tensorの`concat`、`stack`そして`tile`の違いについて、\n",
        "イラストによる例を以下に紹介しましょう。 Ragged Tensorでの結合では、\n",
        "それぞれの行でそのままの形を保ったまま単一の行を形成していきます。\n",
        "\n",
        "\n",
        "![ragged_concat](https://www.tensorflow.org/images/ragged_tensors/ragged_concat.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ush7IGUWLXIn",
        "colab": {}
      },
      "source": [
        "ragged_x = tf.ragged.constant([[\"John\"], [\"a\", \"big\", \"dog\"], [\"my\", \"cat\"]])\n",
        "ragged_y = tf.ragged.constant([[\"fell\", \"asleep\"], [\"barked\"], [\"is\", \"fuzzy\"]])\n",
        "print(tf.concat([ragged_x, ragged_y], axis=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pvQzZG8zMoWa"
      },
      "source": [
        "しかし、sparse tensorでの結合は、以下のイラストで示す通り、密テンソルでの結合と同様に行われます。 \n",
        "(Øは欠損値を表します)\n",
        "\n",
        "\n",
        "![sparse_concat](https://www.tensorflow.org/images/ragged_tensors/sparse_concat.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eTIhGayQL0gI",
        "colab": {}
      },
      "source": [
        "sparse_x = ragged_x.to_sparse()\n",
        "sparse_y = ragged_y.to_sparse()\n",
        "sparse_result = tf.sparse.concat(sp_inputs=[sparse_x, sparse_y], axis=1)\n",
        "print(tf.sparse.to_dense(sparse_result, ''))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Vl8eQN8pMuYx"
      },
      "source": [
        "またこのような区別がもたらす重要な違いについて、別の例として一つ紹介しましょう。\n",
        "例えば、各行の平均値を知りたいとき、`tf.reduce_mean`オペレーションを使用しますが、\n",
        "Ragged Tensorでは各行の長さで平均分母をとりますが、一方のSparse Tensorでは全体での長さの値が\n",
        "平均分母をとります。(これは行の中で一番長い行か、別に設定されたそれ以上の値をとります）\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cRcHzS6pcHYC"
      },
      "source": [
        "## オーバーロード演算子\n",
        "`Ragged Tensor`　クラスはPythonの算術演算子や比較演算子などをオーバーロードしています。\n",
        "要素同士の計算については簡単に実装することができます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "skScd37P-PVu",
        "colab": {}
      },
      "source": [
        "x = tf.ragged.constant([[1, 2], [3], [4, 5, 6]])\n",
        "y = tf.ragged.constant([[1, 1], [2], [3, 3, 3]])\n",
        "print(x + y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XEGgbZHV-PVw"
      },
      "source": [
        "オーバーロード演算子は要素ごとの計算を行うため、入力は全て同じShapeを持っているか、\n",
        "分散的に入力できる(??)必要があります。 一番シンプルなブロードキャストの例が以下の通りで、\n",
        "単一の数字を入力することでRagged Tensorの各要素に入力することができます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IYybEEWc-PVx",
        "colab": {}
      },
      "source": [
        "x = tf.ragged.constant([[1, 2], [3], [4, 5, 6]])\n",
        "print(x + 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "okGb9dIi-PVz"
      },
      "source": [
        "もっと応用的なケースについては、**ブロードキャスト**の項を参考にしてください。\n",
        "\n",
        "Ragged Tensorのオーバーロード演算子は、通常の`Tensor`と同じように以下の演算子をサポートしています。\n",
        "単項演算子`-`、 `~`そして`abs()`　および　バイナリ演算子`+`, `-`, `*`, `/`,\n",
        "`//`, `%`, `**`, `&`, `|`, `^`, `==`, `<`, `<=`, `>`,`>=`が対応しています。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "f2anbs6ZnFtl"
      },
      "source": [
        "## インデックス指定\n",
        "\n",
        "Ragged TensorはPythonライクなインデックス指定や、多次元的なインデックス指定、\n",
        "Sliceを指定することができます。2次元、3次元でのRagged Tensorの例を以下に示します。\n",
        "\n",
        "\n",
        "### 2次元Ragged Tensor(1次元だけRaggedな次元)のインデックス指定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MbSRZRDz-PV1",
        "colab": {}
      },
      "source": [
        "queries = tf.ragged.constant(\n",
        "    [['Who', 'is', 'George', 'Washington'],\n",
        "     ['What', 'is', 'the', 'weather', 'tomorrow'],\n",
        "     ['Goodnight']])\n",
        "print(queries[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EFfjZV7YA3UH",
        "colab": {}
      },
      "source": [
        "print(queries[1, 2])                # 単語が出現"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VISRPQSdA3xn",
        "colab": {}
      },
      "source": [
        "print(queries[1:])                  # 1行目以外の全て"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J1PpSyKQBMng",
        "colab": {}
      },
      "source": [
        "print(queries[:, :3])               # 各行最初の3単語ずつ"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ixrhHmJBeidy",
        "colab": {}
      },
      "source": [
        "print(queries[:, -2:])              # 各行最後に2単語ずつ"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cnOP6Vza-PV4"
      },
      "source": [
        "### 3次元Ragged Tensor(2次元がRaggedな次元)のインデックス指定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8VbqbKcE-PV6",
        "colab": {}
      },
      "source": [
        "rt = tf.ragged.constant([[[1, 2, 3], [4]],\n",
        "                         [[5], [], [6]],\n",
        "                         [[7]],\n",
        "                         [[8, 9], [10]]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f9WPVWf4grVp",
        "colab": {}
      },
      "source": [
        "print(rt[1])                        # 第二行目 (2次元のRagged Tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ad8FGJoABjQH",
        "colab": {}
      },
      "source": [
        "print(rt[3, 0])                     # 第四行目の最初の要素(1次元のRagged Tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MPPr-a-bBjFE",
        "colab": {}
      },
      "source": [
        "print(rt[:, 1:3])                   # 各行の1~3までの要素(3次元のRagged Tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6SIDeoIUBi4z",
        "colab": {}
      },
      "source": [
        "print(rt[:, -1:])                   # 各行最後の要素(3次元のRagged Tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_d3nBh1GnWvU"
      },
      "source": [
        "\n",
        "`RaggedTensor`は多次元的なインデックス指定とSlice指定をサポートしています。しかし、制約もあります。\n",
        "Raggedな次元でのインデックス指定だけはできません。これはインデックス指定時に、\n",
        "値が存在しているかどうかが不明確だからです。この場合、`IndexError`を出すべきか、\n",
        "与えられた初期値を出すべきか、はたまたスキップして少ない行のテンソルを渡すべきか(??)が、\n",
        "不明瞭だからです。\n",
        "[guiding principles of Python](https://www.python.org/dev/peps/pep-0020/)\n",
        "によれば、曖昧さを否定せよと書かれているので(??)、\n",
        "今の所現在では、Raggedな次元へのインデックス指定はできないように実装しています。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IsWKETULAJbN"
      },
      "source": [
        "## テンソルへの変換\n",
        "\n",
        "`Ragged Tensor`クラスは`tf.Tensor`や`tf.SparseTensors`といった、\n",
        "テンソル型への変換をサポートしています。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "INnfmZGcBoU_",
        "colab": {}
      },
      "source": [
        "ragged_sentences = tf.ragged.constant([\n",
        "    ['Hi'], ['Welcome', 'to', 'the', 'fair'], ['Have', 'fun']])\n",
        "print(ragged_sentences.to_tensor(default_value=''))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "41WAZLXNnbwH",
        "colab": {}
      },
      "source": [
        "print(ragged_sentences.to_sparse())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-rfiyYqne8QN",
        "colab": {}
      },
      "source": [
        "x = [[1, 3, -1, -1], [2, -1, -1, -1], [4, 5, 8, 9]]\n",
        "print(tf.RaggedTensor.from_tensor(x, padding=-1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S8MkYo2hfVhj",
        "colab": {}
      },
      "source": [
        "st = tf.SparseTensor(indices=[[0, 0], [2, 0], [2, 1]],\n",
        "                     values=['a', 'b', 'c'],\n",
        "                     dense_shape=[3, 3])\n",
        "print(tf.RaggedTensor.from_sparse(st))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qx025sNMkAHH"
      },
      "source": [
        "## Evaluating ragged tensors\n",
        "\n",
        "### Eager execution\n",
        "\n",
        "In eager execution mode, ragged tensors are evaluated immediately. To access the\n",
        "values they contain, you can:\n",
        "\n",
        "*   Use the\n",
        "    `tf.RaggedTensor.to_list()`\n",
        "    method, which converts the ragged tensor to a Python `list`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uMm1WMkc-PV_",
        "colab": {}
      },
      "source": [
        "rt = tf.ragged.constant([[1, 2], [3, 4, 5], [6], [], [7]])\n",
        "print(rt.to_list())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SrizmqTc-PWC"
      },
      "source": [
        "*   Use Python indexing. If the tensor piece you select contains no ragged\n",
        "    dimensions, then it will be returned as an `EagerTensor`. You can then use\n",
        "    the `numpy()` method to access the value directly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HpRHhfLe-PWD",
        "colab": {}
      },
      "source": [
        "print(rt[1].numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sNlpI2fR-PWF"
      },
      "source": [
        "*   Decompose the ragged tensor into its components, using the\n",
        "    `tf.RaggedTensor.values`\n",
        "    and\n",
        "    `tf.RaggedTensor.row_splits`\n",
        "    properties, or row-paritioning methods such as `tf.RaggedTensor.row_lengths()`\n",
        "    and `tf.RaggedTensor.value_rowids()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yTckrLdB-PWG",
        "colab": {}
      },
      "source": [
        "print(rt.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B8OnG9NzCEnv",
        "colab": {}
      },
      "source": [
        "print(rt.row_splits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EdljbNPq-PWS"
      },
      "source": [
        "### Broadcasting\n",
        "\n",
        "Broadcasting is the process of making tensors with different shapes have\n",
        "compatible shapes for elementwise operations. For more background on\n",
        "broadcasting, see:\n",
        "\n",
        "*   [Numpy: Broadcasting](https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
        "*   `tf.broadcast_dynamic_shape`\n",
        "*   `tf.broadcast_to`\n",
        "\n",
        "The basic steps for broadcasting two inputs `x` and `y` to have compatible\n",
        "shapes are:\n",
        "\n",
        "1.  If `x` and `y` do not have the same number of dimensions, then add outer\n",
        "    dimensions (with size 1) until they do.\n",
        "\n",
        "2.  For each dimension where `x` and `y` have different sizes:\n",
        "\n",
        "    *   If `x` or `y` have size `1` in dimension `d`, then repeat its values\n",
        "        across dimension `d` to match the other input's size.\n",
        "\n",
        "    *   Otherwise, raise an exception (`x` and `y` are not broadcast\n",
        "        compatible)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-S2hOUWx-PWU"
      },
      "source": [
        "Where the size of a tensor in a uniform dimension is a single number (the size\n",
        "of slices across that dimension); and the size of a tensor in a ragged dimension\n",
        "is a list of slice lengths (for all slices across that dimension).\n",
        "\n",
        "#### Broadcasting examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0n095XdR-PWU",
        "colab": {}
      },
      "source": [
        "# x       (2D ragged):  2 x (num_rows)\n",
        "# y       (scalar)\n",
        "# result  (2D ragged):  2 x (num_rows)\n",
        "x = tf.ragged.constant([[1, 2], [3]])\n",
        "y = 3\n",
        "print(x + y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0SVYk5AP-PWW",
        "colab": {}
      },
      "source": [
        "# x         (2d ragged):  3 x (num_rows)\n",
        "# y         (2d tensor):  3 x          1\n",
        "# Result    (2d ragged):  3 x (num_rows)\n",
        "x = tf.ragged.constant(\n",
        "   [[10, 87, 12],\n",
        "    [19, 53],\n",
        "    [12, 32]])\n",
        "y = [[1000], [2000], [3000]]\n",
        "print(x + y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MsfBMD80s8Ux",
        "colab": {}
      },
      "source": [
        "# x      (3d ragged):  2 x (r1) x 2\n",
        "# y      (2d ragged):         1 x 1\n",
        "# Result (3d ragged):  2 x (r1) x 2\n",
        "x = tf.ragged.constant(\n",
        "    [[[1, 2], [3, 4], [5, 6]],\n",
        "     [[7, 8]]],\n",
        "    ragged_rank=1)\n",
        "y = tf.constant([[10]])\n",
        "print(x + y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rEj5QVfnva0t",
        "colab": {}
      },
      "source": [
        "# x      (3d ragged):  2 x (r1) x (r2) x 1\n",
        "# y      (1d tensor):                    3\n",
        "# Result (3d ragged):  2 x (r1) x (r2) x 3\n",
        "x = tf.ragged.constant(\n",
        "    [\n",
        "        [\n",
        "            [[1], [2]],\n",
        "            [],\n",
        "            [[3]],\n",
        "            [[4]],\n",
        "        ],\n",
        "        [\n",
        "            [[5], [6]],\n",
        "            [[7]]\n",
        "        ]\n",
        "    ],\n",
        "    ragged_rank=2)\n",
        "y = tf.constant([10, 20, 30])\n",
        "print(x + y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uennZ64Aqftb"
      },
      "source": [
        "Here are some examples of shapes that do not broadcast:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UpI0FlfL4Eim",
        "colab": {}
      },
      "source": [
        "# x      (2d ragged): 3 x (r1)\n",
        "# y      (2d tensor): 3 x    4  # trailing dimensions do not match\n",
        "x = tf.ragged.constant([[1, 2], [3, 4, 5, 6], [7]])\n",
        "y = tf.constant([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n",
        "try:\n",
        "  x + y\n",
        "except tf.errors.InvalidArgumentError as exception:\n",
        "  print(exception)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qGq1zOT4zMoc",
        "colab": {}
      },
      "source": [
        "# x      (2d ragged): 3 x (r1)\n",
        "# y      (2d ragged): 3 x (r2)  # ragged dimensions do not match.\n",
        "x = tf.ragged.constant([[1, 2, 3], [4], [5, 6]])\n",
        "y = tf.ragged.constant([[10, 20], [30, 40], [50]])\n",
        "try:\n",
        "  x + y\n",
        "except tf.errors.InvalidArgumentError as exception:\n",
        "  print(exception)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CvLae5vMqeji",
        "colab": {}
      },
      "source": [
        "# x      (3d ragged): 3 x (r1) x 2\n",
        "# y      (3d ragged): 3 x (r1) x 3  # trailing dimensions do not match\n",
        "x = tf.ragged.constant([[[1, 2], [3, 4], [5, 6]],\n",
        "                        [[7, 8], [9, 10]]])\n",
        "y = tf.ragged.constant([[[1, 2, 0], [3, 4, 0], [5, 6, 0]],\n",
        "                        [[7, 8, 0], [9, 10, 0]]])\n",
        "try:\n",
        "  x + y\n",
        "except tf.errors.InvalidArgumentError as exception:\n",
        "  print(exception)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m0wQkLfV-PWa"
      },
      "source": [
        "## RaggedTensor encoding\n",
        "\n",
        "Ragged tensors are encoded using the `RaggedTensor` class. Internally, each\n",
        "`RaggedTensor` consists of:\n",
        "\n",
        "*   A `values` tensor, which concatenates the variable-length rows into a\n",
        "    flattened list.\n",
        "*   A `row_splits` vector, which indicates how those flattened values are\n",
        "    divided into rows. In particular, the values for row `rt[i]` are stored in\n",
        "    the slice `rt.values[rt.row_splits[i]:rt.row_splits[i+1]]`.\n",
        "\n",
        "![ragged_encoding](https://www.tensorflow.org/images/ragged_tensors/ragged_encoding.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MrLgMu0gPuo-",
        "colab": {}
      },
      "source": [
        "rt = tf.RaggedTensor.from_row_splits(\n",
        "    values=[3, 1, 4, 1, 5, 9, 2],\n",
        "    row_splits=[0, 4, 4, 6, 7])\n",
        "print(rt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bpB7xKoUPtU6"
      },
      "source": [
        "### Multiple ragged dimensions\n",
        "\n",
        "A ragged tensor with multiple ragged dimensions is encoded by using a nested\n",
        "`RaggedTensor` for the `values` tensor. Each nested `RaggedTensor` adds a single\n",
        "ragged dimension.\n",
        "\n",
        "![ragged_rank_2](https://www.tensorflow.org/images/ragged_tensors/ragged_rank_2.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yy3IGT2a-PWb",
        "colab": {}
      },
      "source": [
        "rt = tf.RaggedTensor.from_row_splits(\n",
        "    values=tf.RaggedTensor.from_row_splits(\n",
        "        values=[10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
        "        row_splits=[0, 3, 3, 5, 9, 10]),\n",
        "    row_splits=[0, 1, 1, 5])\n",
        "print(rt)\n",
        "print(\"Shape: {}\".format(rt.shape))\n",
        "print(\"Number of ragged dimensions: {}\".format(rt.ragged_rank))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5HqEEDzk-PWc"
      },
      "source": [
        "The factory function `tf.RaggedTensor.from_nested_row_splits` may be used to construct a\n",
        "RaggedTensor with multiple ragged dimensions directly, by providing a list of\n",
        "`row_splits` tensors:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AKYhtFcT-PWd",
        "colab": {}
      },
      "source": [
        "rt = tf.RaggedTensor.from_nested_row_splits(\n",
        "    flat_values=[10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
        "    nested_row_splits=([0, 1, 1, 5], [0, 3, 3, 5, 9, 10]))\n",
        "print(rt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uba2EnAY-PWf"
      },
      "source": [
        "### Uniform Inner Dimensions\n",
        "\n",
        "Ragged tensors with uniform inner dimensions are encoded by using a\n",
        "multidimensional `tf.Tensor` for `values`.\n",
        "\n",
        "![uniform_inner](https://www.tensorflow.org/images/ragged_tensors/uniform_inner.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z2sHwHdy-PWg",
        "colab": {}
      },
      "source": [
        "rt = tf.RaggedTensor.from_row_splits(\n",
        "    values=[[1, 3], [0, 0], [1, 3], [5, 3], [3, 3], [1, 2]],\n",
        "    row_splits=[0, 3, 4, 6])\n",
        "print(rt)\n",
        "print(\"Shape: {}\".format(rt.shape))\n",
        "print(\"Number of ragged dimensions: {}\".format(rt.ragged_rank))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8yYaNrgX-PWh"
      },
      "source": [
        "### Alternative row-partitioning schemes\n",
        "\n",
        "The `RaggedTensor` class uses `row_splits` as the primary mechanism to store\n",
        "information about how the values are partitioned into rows. However,\n",
        "`RaggedTensor` also provides support for four alternative row-partitioning\n",
        "schemes, which can be more convenient to use depending on how your data is\n",
        "formatted. Internally, `RaggedTensor` uses these additional schemes to improve\n",
        "efficiency in some contexts.\n",
        "\n",
        "<dl>\n",
        "  <dt>Row lengths</dt>\n",
        "    <dd>`row_lengths` is a vector with shape `[nrows]`, which specifies the\n",
        "    length of each row.</dd>\n",
        "\n",
        "  <dt>Row starts</dt>\n",
        "    <dd>`row_starts` is a vector with shape `[nrows]`, which specifies the start\n",
        "    offset of each row. Equivalent to `row_splits[:-1]`.</dd>\n",
        "\n",
        "  <dt>Row limits</dt>\n",
        "    <dd>`row_limits` is a vector with shape `[nrows]`, which specifies the stop\n",
        "    offset of each row. Equivalent to `row_splits[1:]`.</dd>\n",
        "\n",
        "  <dt>Row indices and number of rows</dt>\n",
        "    <dd>`value_rowids` is a vector with shape `[nvals]`, corresponding\n",
        "    one-to-one with values, which specifies each value's row index. In\n",
        "    particular, the row `rt[row]` consists of the values `rt.values[j]` where\n",
        "    `value_rowids[j]==row`. \\\n",
        "    `nrows` is an integer that specifies the number of rows in the\n",
        "    `RaggedTensor`. In particular, `nrows` is used to indicate trailing empty\n",
        "    rows.</dd>\n",
        "</dl>\n",
        "\n",
        "For example, the following ragged tensors are equivalent:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4TH6XoQ8-PWh",
        "colab": {}
      },
      "source": [
        "values = [3, 1, 4, 1, 5, 9, 2, 6]\n",
        "print(tf.RaggedTensor.from_row_splits(values, row_splits=[0, 4, 4, 7, 8, 8]))\n",
        "print(tf.RaggedTensor.from_row_lengths(values, row_lengths=[4, 0, 3, 1, 0]))\n",
        "print(tf.RaggedTensor.from_row_starts(values, row_starts=[0, 4, 4, 7, 8]))\n",
        "print(tf.RaggedTensor.from_row_limits(values, row_limits=[4, 4, 7, 8, 8]))\n",
        "print(tf.RaggedTensor.from_value_rowids(\n",
        "    values, value_rowids=[0, 0, 0, 0, 2, 2, 2, 3], nrows=5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZGRrpwxjsOGr"
      },
      "source": [
        "The RaggedTensor class defines methods which can be used to construct\n",
        "each of these row-partitioning tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fIdn-hUBsoSj",
        "colab": {}
      },
      "source": [
        "rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])\n",
        "print(\"      values: {}\".format(rt.values))\n",
        "print(\"  row_splits: {}\".format(rt.row_splits))\n",
        "print(\" row_lengths: {}\".format(rt.row_lengths()))\n",
        "print(\"  row_starts: {}\".format(rt.row_starts()))\n",
        "print(\"  row_limits: {}\".format(rt.row_limits()))\n",
        "print(\"value_rowids: {}\".format(rt.value_rowids()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2r9XUpLUsdOa"
      },
      "source": [
        "(Note that `tf.RaggedTensor.values` and `tf.RaggedTensors.row_splits` are properties, while the remaining row-partitioning accessors are all methods.  This reflects the fact that the `row_splits` are the primary underlying representation, and the other row-partitioning tensors must be computed.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NBX15kEr-PWi"
      },
      "source": [
        "Some of the advantages and disadvantages of the different row-partitioning\n",
        "schemes are:\n",
        "\n",
        "+ **Efficient indexing**:\n",
        "    The `row_splits`, `row_starts`, and `row_limits` schemes all enable\n",
        "    constant-time indexing into ragged tensors. The `value_rowids` and\n",
        "     `row_lengths` schemes do not.\n",
        "\n",
        "+ **Small encoding size**:\n",
        "    The `value_rowids` scheme is more efficient when storing ragged tensors that\n",
        "    have a large number of empty rows, since the size of the tensor depends only\n",
        "    on the total number of values. On the other hand, the other four encodings\n",
        "    are more efficient when storing ragged tensors with longer rows, since they\n",
        "    require only one scalar value for each row.\n",
        "\n",
        "+ **Efficient concatenation**:\n",
        "   The `row_lengths` scheme is more efficient when concatenating ragged\n",
        "    tensors, since row lengths do not change when two tensors are concatenated\n",
        "   together (but row splits and row indices do).\n",
        "\n",
        "+ **Compatibility**:\n",
        "    The `value_rowids` scheme matches the\n",
        "    [segmentation](../api_guides/python/math_ops.md#Segmentation)\n",
        "    format used by operations such as `tf.segment_sum`. The `row_limits` scheme\n",
        "    matches the format used by ops such as `tf.sequence_mask`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R2lzYuYrNmw6",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}